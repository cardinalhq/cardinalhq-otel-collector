apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    {{- include "customerside.labels" . | nindent 4 }}
    app.kubernetes.io/component: collector-l1
  {{- include "customerside.configMap.annotations" . | nindent 2 }}
  name: {{ include "customerside.fullname" . }}-collector-config-l1
  {{- include "customerside.namespace" . | nindent 2 }}
data:
  config.yaml: |-
    receivers:
      otlp/l1:
        protocols:
          grpc:
            endpoint: 0.0.0.0:{{ .Values.collector.ports.incoming.otlpGRPCPort }}
          http:
            endpoint: 0.0.0.0:{{ .Values.collector.ports.incoming.otlpHTTPPort }}
      chqdatadog/l1:
        endpoint: 0.0.0.0:{{ .Values.collector.ports.incoming.datadogPort }}

    exporters:
      loadbalancing/metrics:
        routing_key: "metric"
        protocol:
          otlp:
            tls:
              insecure: true
            sending_queue:
              queue_size: 2000
            retry_on_failure:
              enabled: true
              max_elapsed_time: 1m
              initial_interval: 1s
              max_interval: 10s
        resolver:
          k8s:
            service: "{{ include "customerside.fullname" . }}-collector-l2.${env:POD_NAMESPACE}"
            ports:
              - {{ .Values.collector.ports.internal.otlpGRPCPort }}
      loadbalancing/traces:
        routing_key: "traceID"
        protocol:
          otlp:
            tls:
              insecure: true
            sending_queue:
              queue_size: 2000
            retry_on_failure:
              enabled: true
              max_elapsed_time: 1m
              initial_interval: 1s
              max_interval: 10s
        resolver:
          k8s:
            service: "{{ include "customerside.name" . }}-collector-l2.${env:POD_NAMESPACE}"
            ports:
              - {{ .Values.collector.ports.internal.otlpGRPCPort }}
      chqdatadog/cardinalhq:
        api_key: ${env:DATADOG_API_KEY}
        metrics:
          endpoint: {{ .Values.collector.endpoints.datadog.metrics }}
          compression: {{ .Values.collector.endpoints.datadog.compression }}
        logs:
          endpoint: {{ .Values.collector.endpoints.datadog.logs }}
          compression: {{ .Values.collector.endpoints.datadog.compression }}
        traces:
          endpoint: {{ .Values.collector.endpoints.datadog.traces }}
          compression: {{ .Values.collector.endpoints.datadog.compression }}

      otlp/tochq:
        endpoint: {{ .Values.collector.endpoints.cardinalHQ.otlpGRPC}}
        headers:
          x-cardinalhq-api-key: "${env:CARDINALHQ_API_KEY}"

      chqstats/raw:
        endpoint: {{ .Values.collector.endpoints.cardinalHQ.stats }}
        api_key: ${env:CARDINALHQ_API_KEY}
        interval: {{ .Values.collector.endpoints.cardinalHQ.statsInterval }}
        phase: presample

      chqstats/datadog:
        endpoint: {{ .Values.collector.endpoints.cardinalHQ.stats }}
        api_key: ${env:CARDINALHQ_API_KEY}
        interval: {{ .Values.collector.endpoints.cardinalHQ.statsInterval }}
        phase: postsample
        vendor: datadog

    processors:
      # Limit collector process memory usage.  This should be the first processor
      # in the processor list.
      memory_limiter/csl1:
        limit_mib: 1500
        spike_limit_mib: 100
        check_interval: 5s

      # Batch processors to limit the size and/or timeframe that telemetry
      # is batched before being sent to the exporters.  This should be
      # the last item in the processor list.
      batch/csl1logs:
        timeout: 1s
        send_batch_size: 100
        send_batch_max_size: 1000
      
      # This processor should be added to the list of processors before
      # the filter/toprovider, and the exporters that write to S3 or to upstream
      # providers, such as Datadog.  It will add attributes to the telemetry
      # which will allow selectively sending metrics on to the upstream
      # provider.  This markup is also written to S3 for later processing
      # by CardinalHQ.
      chqdecorator/csl1:
        sampler_config_file: {{ .Values.collector.endpoints.cardinalHQ.samplerConfig }}
        api_key: ${env:CARDINALHQ_API_KEY}
        traces:
          uninteresting_rate: 1000
          has_error_rate: 4

      # This processor should be added to the list of processors that
      # are in the pipeline destined to the upstream provider, such as
      # Datadog.  It should NOT be used to filter output to S3 for
      # later processing by CardinalHQ.
      filter/toprovider:
        error_mode: ignore
        logs:
          log_record:
            - 'attributes["_cardinalhq.filtered"] == true'
        metrics:
          datapoint:
            - 'attributes["_cardinalhq.filtered"] == true'
        traces:
          span:
            - 'attributes["_cardinalhq.filtered"] == true'

      # Items marked with _cardinalhq.aggregated_output are not sent to
      # CardinalHQ, as the metrics they represent would already be
      # included in the detailed metrics.
      filter/tochq:
        error_mode: ignore
        logs:
          log_record:
            - 'attributes["_cardinalhq.aggregated_output"] == true'
        metrics:
          datapoint:
            - 'attributes["_cardinalhq.aggregated_output"] == true'
        traces:
          span:
            - 'attributes["_cardinalhq.aggregated_output"] == true'

      # This processor should be added to the list of processors that
      # are in the pipeline destined to the upstream provider, such as
      # Datadog.  It should NOT be used to filter output sent to
      # CardinalHQ.
      attributes/toprovider:
        actions:
          - action: delete
            pattern: '^_cardinalhq.*'

    connectors:
      forward/toprovider:
        
    service:
      pipelines:

        # log handling.  No need to partition here.
        logs/chq:
          receivers: [otlp/l1, chqdatadog/l1]
          processors: [memory_limiter/csl1, chqdecorator/csl1, batch/csl1logs]
          exporters: [otlp/tochq, chqstats/raw, forward/toprovider]
        logs/toprovider:
          receivers: [forward/toprovider]
          processors: [filter/toprovider, attributes/toprovider]
          exporters: [chqdatadog/cardinalhq, chqstats/datadog]

        # metric handling.  Partition on metric name so aggregations
        # work properly.  TODO: modify aggregator to add artificial attribute
        # for the host that processed the aggregation, and let the receiver
        # just get more than one time series for our aggregation.
        metrics/l1:
          receivers: [otlp/l1, chqdatadog/l1]
          processors: [memory_limiter/csl1]
          exporters: [loadbalancing/metrics]

        # trace handling.  Partition on trace ID so we can group traces
        # and filter based on the entire trace, not individual spans.
        traces/l1:
          receivers: [otlp/l1, chqdatadog/l1]
          processors: [memory_limiter/csl1]
          exporters: [loadbalancing/traces]

      {{ toYaml .Values.selfTelemetry | nindent 6 }}

      extensions:
        - zpages
        - health_check

    extensions:
      zpages:
        endpoint: "0.0.0.0:{{ .Values.collector.endpoints.zpages.port }}"
      health_check:
        endpoint: "0.0.0.0:{{ .Values.collector.endpoints.healthz.port }}"
        path: {{ .Values.collector.endpoints.healthz.path }}
